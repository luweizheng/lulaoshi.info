---
title: Table API & SQLç»¼è¿°
keywords: 
  - Flink
  - Table API
  - Flink SQL
  - Blink Planner
  - Flink Planner
description: "Flink Table API & SQLç»¼è¿°"
---

import { Typography, Grid } from "@material-ui/core";
import { FontAwesomeIcon } from "@fortawesome/react-fontawesome";
import { faGithub } from "@fortawesome/free-brands-svg-icons";

<Grid container className="upper-note" spacing={1} direction="row" justifyContent="center" alignItems="center">
    <Grid item md={1} lg={1} />
    <Grid item xs={3} md={2} lg={2}>
        <img src="/img/flink-book.jpeg" /> 
    </Grid>
    <Grid item xs={8} md={8} lg={8}>
        æœ¬æ•™ç¨‹å·²å‡ºç‰ˆä¸ºã€ŠFlinkåŸç†ä¸å®è·µã€‹ï¼Œæ„Ÿå…´è¶£çš„è¯»è€…è¯·åœ¨å„å¤§ç”µå•†å¹³å°è´­ä¹°ï¼Œè°¢è°¢æ”¯æŒï¼
        é…å¥—æºç ğŸ‘‰<a target="_blank" href="https://github.com/luweizheng/flink-tutorials"><FontAwesomeIcon icon={faGithub} size={"1x"} /></a>
    </Grid>
    <Grid item md={2} lg={2} />
</Grid>

Table APIå’ŒSQLä¸¤è€…ç»“åˆéå¸¸ç´§å¯†ï¼Œå®ƒä»¬çš„APIä¸å…³ç³»å‹æ•°æ®åº“ä¸­æŸ¥è¯¢éå¸¸ç›¸ä¼¼ï¼Œæœ¬è´¨ä¸Šå®ƒä»¬éƒ½ä¾èµ–äºä¸€ä¸ªåƒæ•°æ®è¡¨çš„ç»“æ„ï¼š`Table`ã€‚

åœ¨å…·ä½“æ‰§è¡Œå±‚é¢ï¼ŒFlinkå°†Table APIæˆ–SQLè¯­å¥ä½¿ç”¨ä¸€ä¸ªåä¸ºæ‰§è¡Œè®¡åˆ’å™¨ï¼ˆPlannerï¼‰çš„ç»„ä»¶å°†å…³ç³»å‹æŸ¥è¯¢è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„Flinkä½œä¸šï¼Œå¹¶å¯¹ä½œä¸šè¿›è¡Œä¸€äº›ä¼˜åŒ–ã€‚åœ¨æœ¬ä¹¦å†™ä½œæœŸé—´å‡ºç°äº†é˜¿é‡Œå·´å·´çš„Blinkç‰ˆæœ¬çš„Plannerï¼ˆæˆ–è€…ç§°ä¸ºBlink Plannerï¼‰å’ŒFlinkç¤¾åŒºç‰ˆæœ¬çš„è€Plannerï¼ˆæˆ–è€…ç§°ä¸ºFlink Plannerã€Old Plannerï¼‰å¹¶å­˜çš„ç°è±¡ï¼ŒFlinkç¤¾åŒºæ­£åœ¨è¿›è¡Œè¿™æ–¹é¢çš„è¿­ä»£å’Œèåˆã€‚ä»åç§°ä¸­å¯ä»¥çœ‹å‡ºï¼ŒBlink Planneræœªæ¥å°†é€æ­¥å–ä»£Flink Plannerï¼Œè¯»è€…å¯ä»¥æ ¹æ®éœ€æ±‚æ¥ç¡®å®šä½¿ç”¨å“ªç§Plannerã€‚åŒæ—¶ï¼ŒTable API & SQLçš„è¿­ä»£é€Ÿåº¦è¾ƒå¿«ï¼Œè¯»è€…å¯ä»¥æ ¹æ®Flinkå®˜æ–¹æ–‡æ¡£æŸ¥è¯¢æœ€æ–°çš„ä½¿ç”¨æ–¹æ³•ã€‚

æœ¬èŠ‚ä¸»è¦ä»‹ç»Table API & SQLç¨‹åºçš„éª¨æ¶ç»“æ„ä»¥åŠå¦‚ä½•è¿æ¥å¤–éƒ¨ç³»ç»Ÿã€‚

## Table API & SQLç¨‹åºéª¨æ¶ç»“æ„

ä¸‹é¢çš„ä»£ç å±•ç¤ºäº†Table API & SQLçš„éª¨æ¶ç»“æ„ï¼š

```java
// åŸºäºStreamExecutionEnvironmentåˆ›å»ºTableEnvironment
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);

// è¯»å–æ•°æ®æºï¼Œåˆ›å»ºæ•°æ®è¡¨Table
tableEnv.connect(...).createTemporaryTable("user_behavior");
// æ³¨å†Œè¾“å‡ºæ•°æ®è¡¨Table
tableEnv.connect(...).createTemporaryTable("output_table");

// ä½¿ç”¨Table APIæŸ¥è¯¢user_behavior
Table tabApiResult = tableEnv.from("user_behavior").select(...);
// ä½¿ç”¨SQLæŸ¥è¯¢table1
Table sqlResult  = tableEnv.sqlQuery("SELECT ... FROM user_behavior ... ");

// å°†æŸ¥è¯¢ç»“æœè¾“å‡ºåˆ°outputTable
tabApiResult.insertInto("output_table");
sqlResult.insertInto("output_table");

// execute
tableEnv.execute("table");
```

ä»ç¨‹åºéª¨æ¶ç»“æ„ä¸Šæ¥çœ‹ï¼Œç›®å‰çš„Table API & SQLè¦ä¸DataStream/DataSet APIç›¸ç»“åˆæ¥ä½¿ç”¨ï¼Œä¸»è¦éœ€è¦ä»¥ä¸‹æ­¥éª¤ï¼š

1. åˆ›å»ºæ‰§è¡Œç¯å¢ƒï¼ˆExecutionEnvironmentï¼‰å’Œè¡¨ç¯å¢ƒï¼ˆTableEnvironmentï¼‰
2. è·å–æ•°æ®è¡¨`Table`
3. ä½¿ç”¨Table APIæˆ–SQLåœ¨`Table`ä¸ŠåšæŸ¥è¯¢ç­‰æ“ä½œ
4. å°†ç»“æœè¾“å‡ºåˆ°å¤–éƒ¨ç³»ç»Ÿ
5. è°ƒç”¨`execute()`ï¼Œæ‰§è¡Œä½œä¸š

åœ¨çœŸæ­£ç¼–å†™ä¸€ä¸ªä½œä¸šä¹‹å‰ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åœ¨Mavenä¸­æ·»åŠ ç›¸åº”çš„ä¾èµ–ã€‚æ ¹æ®ç”¨æˆ·é€‰æ‹©Javaè¿˜æ˜¯Scalaï¼Œéœ€è¦å¼•ç”¨`flink-table-api-*-bridge`é¡¹ç›®ï¼Œè¿™ä¸ªé¡¹ç›®æ˜¯Table APIä¸DataStream/DataSet APIä¹‹é—´çš„æ¡¥æ¢ã€‚

```
<!-- Java -->
<dependency>
  <groupId>org.apache.flink</groupId>
  <artifactId>flink-table-api-java-bridge_${scala.binary.version}</artifactId>
  <version>${flink.version}</version>
  <scope>provided</scope>
</dependency>
<!-- Scala -->
<dependency>
  <groupId>org.apache.flink</groupId>
  <artifactId>flink-table-api-scala-bridge_${scala.binary.version}</artifactId>
  <version>${flink.version}</version>
  <scope>provided</scope>
</dependency>
```

æ­¤å¤–ï¼Œè¿˜éœ€è¦æ·»åŠ Plannerç›¸å…³ä¾èµ–ï¼š

```
<!-- Flink 1.9ä¹‹å‰å‡é‡‡ç”¨å¼€æºç¤¾åŒºç‰ˆçš„Planner -->
<dependency>
  <groupId>org.apache.flink</groupId>
  <artifactId>flink-table-planner_${scala.binary.version}</artifactId>
  <version>${flink.version}</version>
  <scope>provided</scope>
</dependency>
<!-- Blinkç‰ˆçš„Planner -->
<dependency>
  <groupId>org.apache.flink</groupId>
  <artifactId>flink-table-planner-blink_${scala.binary.version}</artifactId>
  <version>${flink.version}</version>
  <scope>provided</scope>
</dependency>
```

å…¶ä¸­ï¼Œ`${scala.binary.version}`æ˜¯ä½ æ‰€åœ¨ç¯å¢ƒä¸­Scalaçš„ç‰ˆæœ¬å·ï¼Œå¯ä»¥æ˜¯2.11æˆ–2.12ï¼Œ`{flink.version}`æ˜¯æ‰€é‡‡ç”¨çš„Flinkç‰ˆæœ¬å·ã€‚Mavençš„é…ç½®å’Œå‚æ•°å¯ä»¥å‚è€ƒæœ¬ä¹¦æä¾›çš„æ ·ä¾‹ç¨‹åºä¸­çš„`pom.xml`æ–‡ä»¶ã€‚

## åˆ›å»ºTableEnvironment

`TableEnvironment`æ˜¯Table API & SQLç¼–ç¨‹ä¸­æœ€åŸºç¡€çš„ç±»ï¼Œä¹Ÿæ˜¯æ•´ä¸ªç¨‹åºçš„å…¥å£ï¼Œå®ƒåŒ…å«äº†ç¨‹åºçš„æ ¸å¿ƒä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚`TableEnvironment`çš„æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š

* è¿æ¥å¤–éƒ¨ç³»ç»Ÿ
* å‘ç›®å½•ï¼ˆCatalogï¼‰ä¸­æ³¨å†Œ`Table`æˆ–è€…ä»ä¸­è·å–`Table`
* æ‰§è¡ŒTable APIæˆ–SQLæ“ä½œ
* æ³¨å†Œç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°
* æä¾›ä¸€äº›å…¶ä»–é…ç½®åŠŸèƒ½

åœ¨Flinkç¤¾åŒºå¯¹æœªæ¥çš„è§„åˆ’ä¸­ï¼Œ`TableEnvironment`å°†ç»Ÿä¸€æµæ‰¹å¤„ç†ï¼Œå…¼å®¹Javaå’ŒScalaä¸¤ç§è¯­è¨€ã€‚æˆ‘ä»¬åœ¨ç¬¬å››ç« Flinkçš„éª¨æ¶ç»“æ„ä¸­æ›¾æåˆ°ï¼Œåœ¨Flink 1.10ä¸­ï¼Œé’ˆå¯¹æµå¤„ç†å’Œæ‰¹å¤„ç†åˆ†åˆ«ä½¿ç”¨äº†`StreamExecutionEnvironment`å’Œ`ExecutionEnvironment`ä¸¤å¥—æ‰§è¡Œç¯å¢ƒï¼Œåº•å±‚æœ‰äº›é€»è¾‘è¿˜æ²¡å®Œå…¨ç»Ÿä¸€ï¼ŒåŠ ä¸ŠJavaå’ŒScalaä¸¤ç§è¯­è¨€çš„åŒºåˆ«ï¼Œä»…æ‰§è¡Œç¯å¢ƒå°±å››ç§ä¹‹å¤šã€‚åœ¨Table API & SQLä¸­ï¼Œ`TableEnvironment`ä¹Ÿæ²¡æœ‰å®Œå…¨å°†ä¸Šè¿°é—®é¢˜ç»Ÿä¸€ï¼Œå†åŠ ä¸ŠBlink Plannerä¸åŸæœ‰è€Plannerçš„åŒºåˆ«ï¼Œè¯»è€…åœ¨ç¼–ç¨‹æ—¶ä¸€å®šè¦æ³¨æ„å¦‚ä½•åˆå§‹åŒ–çš„`TableEnvironment`ã€‚

![Flink 1.10ä¸­ä¿ç•™äº†5ä¸ªTableEnvironment](./img/environment.png)

ä»ä¸Šå›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼ŒFlink 1.10ä¿ç•™äº†5ä¸ª`TableEnvironment`ã€‚å…¶ä¸­ï¼Œ`TableEnvironment`æ˜¯æœ€é¡¶çº§çš„æ¥å£ï¼Œ`StreamTableEnvironment`å’Œ`BatchTableEnvironment`éƒ½æä¾›äº†Javaå’ŒScalaä¸¤ä¸ªå®ç°ï¼š

* `org.apache.flink.table.api.TableEnvironment`ï¼šå…¼å®¹Javaå’ŒScalaï¼Œç»Ÿä¸€æµæ‰¹å¤„ç†ï¼Œé€‚ç”¨äºæ•´ä¸ªä½œä¸šéƒ½ä½¿ç”¨ Table API & SQL ç¼–å†™ç¨‹åºçš„åœºæ™¯ã€‚
* `org.apache.flink.table.api.java.StreamTableEnvironment`å’Œ`org.apache.flink.table.api.scala.StreamTableEnvironment`ï¼šåˆ†åˆ«ç”¨äºJavaå’ŒScalaçš„æµå¤„ç†åœºæ™¯ï¼Œæä¾›äº†`DataStream`å’Œ`Table`ä¹‹é—´ç›¸äº’è½¬æ¢çš„æ¥å£ã€‚å¦‚æœä½œä¸šé™¤äº†åŸºäºTable API & SQLå¤–ï¼Œè¿˜æœ‰å’Œ`DataStream`ä¹‹é—´çš„è½¬åŒ–ï¼Œåˆ™éœ€è¦ä½¿ç”¨`StreamTableEnvironment`ã€‚
* `org.apache.flink.table.api.java.BatchTableEnvironment`å’Œ`org.apache.flink.table.api.scala.BatchTableEnvironment`ï¼šåˆ†åˆ«ç”¨äºJavaå’ŒScalaçš„æ‰¹å¤„ç†åœºæ™¯ï¼Œæä¾›äº†`DataSet`å’Œ`Table`ä¹‹é—´ç›¸äº’è½¬æ¢çš„æ¥å£ã€‚å¦‚æœä½œä¸šé™¤äº†åŸºäºTable API & SQLå¤–ï¼Œè¿˜æœ‰å’Œ`DataSet`ä¹‹é—´çš„è½¬åŒ–ï¼Œåˆ™ä½¿ç”¨`BatchTableEnvironment`ã€‚

ä¸‹é¢çš„ä»£ç ä½¿ç”¨Javaè¯­è¨€è¿›è¡Œæµå¤„ç†ï¼Œå®ƒåŸºäºè€Planneråˆ›å»º`TableEnvironment`ã€‚

```java
// ä½¿ç”¨Javaå’Œè€Plannerè¿›è¡Œæµå¤„ç†
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.EnvironmentSettings;
import org.apache.flink.table.api.java.StreamTableEnvironment;

// ä½¿ç”¨è€Planneræ³¨æ„ç›¸åº”çš„PlanneråŒ…è¦åŠ å…¥åˆ°Mavenä¸­
EnvironmentSettings fsSettings = EnvironmentSettings.newInstance().useOldPlanner().inStreamingMode().build();
// åŸºäºStreamExecutionEnvironmentåˆ›å»ºStreamTableEnvironment
StreamExecutionEnvironment fsEnv = StreamExecutionEnvironment.getExecutionEnvironment();
StreamTableEnvironment fsTableEnv = StreamTableEnvironment.create(fsEnv, fsSettings);
// æˆ–è€…åŸºäºTableEnvironment
TableEnvironment fsTableEnv = TableEnvironment.create(fsSettings);
```

å¦‚æœæƒ³åŸºäºBlink Plannerè¿›è¡Œæµå¤„ç†ï¼Œé‚£ä¹ˆéœ€è¦æ”¹ä¸ºï¼š

```java
// ä½¿ç”¨Javaå’ŒBlink Plannerè¿›è¡Œæµå¤„ç†
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.EnvironmentSettings;
import org.apache.flink.table.api.java.StreamTableEnvironment;

// ä½¿ç”¨Blink Planneræ³¨æ„ç›¸åº”çš„PlanneråŒ…è¦åŠ å…¥åˆ°Mavenä¸­
EnvironmentSettings bsSettings = 
EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();
// åŸºäºStreamExecutionEnvironmentåˆ›å»ºStreamTableEnvironment
StreamExecutionEnvironment bsEnv = StreamExecutionEnvironment.getExecutionEnvironment();
StreamTableEnvironment bsTableEnv = StreamTableEnvironment.create(bsEnv, bsSettings);
// æˆ–è€…åŸºäºTableEnvironment
TableEnvironment bsTableEnv = TableEnvironment.create(bsSettings);
```

å¦‚æœæƒ³åŸºäºè€Plannerè¿›è¡Œæ‰¹å¤„ç†ï¼š

```java
// ä½¿ç”¨Javaå’Œè€Plannerè¿›è¡Œæ‰¹å¤„ç†
import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.table.api.java.BatchTableEnvironment;

ExecutionEnvironment fbEnv = ExecutionEnvironment.getExecutionEnvironment();
BatchTableEnvironment fbTableEnv = BatchTableEnvironment.create(fbEnv);
```

åŸºäºBlink Plannerè¿›è¡Œæ‰¹å¤„ç†ï¼š

```java
// ä½¿ç”¨Javaå’ŒBlink Plannerè¿›è¡Œæ‰¹å¤„ç†
import org.apache.flink.table.api.EnvironmentSettings;
import org.apache.flink.table.api.TableEnvironment;

EnvironmentSettings bbSettings = EnvironmentSettings.newInstance().useBlinkPlanner().inBatchMode().build();
TableEnvironment bbTableEnv = TableEnvironment.create(bbSettings);
```

æ€»ç»“ä¸‹æ¥ï¼Œä½¿ç”¨Table API & SQLä¹‹å‰ï¼Œè¦ç¡®å®šä½¿ç”¨ä½•ç§ç¼–ç¨‹è¯­è¨€ï¼ˆJava/Scalaï¼‰ï¼Œè¿›è¡Œæ‰¹å¤„ç†è¿˜æ˜¯æµå¤„ç†ä»¥åŠä½¿ç”¨å“ªç§Plannerã€‚

## è·å–Table

åœ¨å…³ç³»å‹æ•°æ®åº“ä¸­ï¼Œè¡¨æ˜¯æè¿°æ•°æ®çš„åŸºæœ¬å•å…ƒã€‚æ•°æ®åº“è¡¨ä¸€èˆ¬ç”±è¡Œå’Œåˆ—ç»„æˆï¼Œå¦‚æœä»¥ç”µå•†ç”¨æˆ·è¡Œä¸ºæ•°æ®ä¸ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™å¼ è¡¨ç†è§£ä¸ºä¸€ä¸ªExcelè¡¨æ ¼ï¼Œæ¯ä¸€åˆ—ä»£è¡¨ä¸€ç§å±æ€§ï¼Œæ¯”å¦‚`user_id`ã€`behavior`ç­‰ï¼Œæ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªç”¨æˆ·çš„ä¸€æ¬¡è¡Œä¸ºï¼Œæ¯”å¦‚æŸä¸ªç”¨æˆ·åœ¨å“ªä¸ªæ—¶é—´å¯¹å“ªäº›å•†å“äº§ç”Ÿäº†å“ªäº›è¡Œä¸ºã€‚æˆ‘ä»¬ä¸€èˆ¬ç”¨è¡¨æ¨¡å¼ï¼ˆSchemaï¼‰æ¥æè¿°ä¸€ä¸ªè¡¨ä¸­æœ‰å“ªäº›åˆ—ï¼Œè¿™äº›åˆ—çš„æ•°æ®ç±»å‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å®šä¹‰ç”µå•†ç”¨æˆ·è¡Œä¸ºçš„Schemaä¸ºï¼š

```java
Schema schema = new Schema()
                .field("user_id", DataTypes.BIGINT())
                .field("item_id", DataTypes.BIGINT())
                .field("category", DataTypes.BIGINT())
                .field("behavior", DataTypes.STRING())
                .field("ts", DataTypes.TIMESTAMP(3));
```

åœ¨ä¼ ç»Ÿçš„å…³ç³»å‹æ•°æ®åº“ä¸­ï¼Œæ•°æ®åº“è¡¨ä¸€èˆ¬ç”±å¼€å‘è€…å®šä¹‰å¥½ï¼Œåœ¨åç»­å¯¹å¤–åœ°æä¾›æœåŠ¡è¿‡ç¨‹ä¸­ï¼Œè¡¨æ˜¯å¸¸é©»æ•°æ®åº“çš„ï¼Œå¼€å‘è€…ä¸æ–­åœ¨è¡¨ä¸Šè¿›è¡Œå¢åˆ æŸ¥æ”¹ã€‚åœ¨æ•°æ®åˆ†æé¢†åŸŸï¼Œè¡¨çš„æ¦‚å¿µè¢«æ‹“å±•ï¼Œè¡¨ä¸ä»…åŒ…æ‹¬äº†å…³ç³»å‹æ•°æ®åº“ä¸­ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„è¡¨ï¼Œä¹ŸåŒ…æ‹¬äº†å­˜å‚¨æ•°æ®çš„æ–‡ä»¶ï¼Œå¯ä»¥ä¼ è¾“æ•°æ®çš„æ¶ˆæ¯é˜Ÿåˆ—ç­‰ã€‚Flinkæ˜¯ä¸€ä¸ªè®¡ç®—å¼•æ“ï¼Œå®ƒä¸æä¾›æ•°æ®å­˜å‚¨çš„åŠŸèƒ½ï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡Connectorå»è¿æ¥ä¸åŒçš„å¤–éƒ¨ç³»ç»Ÿã€‚ä¸ºäº†åŸºäºå¤–éƒ¨æ•°æ®è¿›è¡ŒTable API & SQLè®¡ç®—ï¼ŒFlinkä½¿ç”¨`Table`çš„æ¦‚å¿µè¡¨ç¤ºå¹¿ä¹‰ä¸Šçš„è¡¨ã€‚å®ƒåŒ…æ‹¬ç‰©ç†ä¸Šç¡®å®å­˜åœ¨çš„è¡¨ï¼Œä¹ŸåŒ…æ‹¬åŸºäºç‰©ç†è¡¨ç»è¿‡ä¸€äº›è®¡ç®—è€Œç”Ÿæˆçš„è™šæ‹Ÿè¡¨ï¼Œè™šæ‹Ÿè¡¨åˆè¢«ç§°ä¸ºè§†å›¾ï¼ˆViewï¼‰ã€‚

å¯è§ï¼Œå¦‚æœæƒ³åœ¨Flinkä¸­ä½¿ç”¨`Table`æ¥æŸ¥è¯¢æ•°æ®ï¼Œæœ€é‡è¦çš„ä¸€æ­¥æ˜¯å°†æ•°æ®ï¼ˆæ•°æ®åº“ã€æ–‡ä»¶æˆ–æ¶ˆæ¯é˜Ÿåˆ—ï¼‰è¯»å–å¹¶è½¬åŒ–æˆä¸€ä¸ª`Table`ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä¸€ä¸ªFlinkä½œä¸šè¿è¡Œæ—¶æ³¨å†Œä¸€ä¸ªæ–°çš„`Table`ï¼Œä¹Ÿå¯ä»¥è·å–å·²åˆ›å»ºå¥½çš„å¸¸é©»é›†ç¾¤çš„`Table`ã€‚åœ¨æ¯ä¸ªFlinkä½œä¸šå¯åŠ¨åä¸´æ—¶åˆ›å»ºçš„è¡¨æ˜¯ä¸´æ—¶è¡¨ï¼ˆTemporary Tableï¼‰ï¼Œéšç€è¿™ä¸ªFlinkä½œä¸šçš„ç»“æŸï¼Œè¿™ç§è¡¨ä¹Ÿè¢«é”€æ¯ï¼Œå®ƒåªèƒ½åœ¨ä¸€ä¸ªFlink Sessionä¸­ä½¿ç”¨ã€‚åœ¨éª¨æ¶ç¨‹åºä¸­`tableEnv.connect(...).createTemporaryTable("user_behavior");`å°±æ˜¯åˆ›å»ºäº†ä¸€ä¸ªTemporary Tableã€‚ä½†æ˜¯æ›´å¤šçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æƒ³è·Ÿä¼ ç»Ÿçš„æ•°æ®åº“é‚£æ ·æå‰åˆ›å»ºå¥½è¡¨ï¼Œè¿™äº›è¡¨åç»­å¯ä»¥ä¸ºæ•´ä¸ªé›†ç¾¤ä¸Šçš„æ‰€æœ‰ç”¨æˆ·å’Œæ‰€æœ‰ä½œä¸šæä¾›æœåŠ¡ï¼Œè¿™ç§è¡¨è¢«ç§°ä¸ºå¸¸é©»è¡¨ï¼ˆPermanent Tableï¼‰ã€‚Permanent Tableå¯ä»¥åœ¨å¤šä¸ªFlink Sessionä¸­ä½¿ç”¨ã€‚

ä¸ºäº†ç®¡ç†å¤šä¸ªPermanent Tableï¼ŒFlinkä½¿ç”¨Catalogæ¥ç»´æŠ¤å¤šä¸ªPermanent Tableçš„åå­—ã€ç±»å‹ï¼ˆæ–‡ä»¶ã€æ¶ˆæ¯é˜Ÿåˆ—æˆ–æ•°æ®åº“ï¼‰ã€æ•°æ®å­˜å‚¨ä½ç½®ç­‰å…ƒæ•°æ®ï¼ˆMetadataï¼‰ä¿¡æ¯ã€‚ä¸€ä¸ªFlinkä½œä¸šå¯ä»¥è¿æ¥æŸä¸ªCatalogï¼Œè¿™æ ·å°±å¯ä»¥ç›´æ¥è¯»å–å…¶ä¸­çš„å„ä¸ªè¡¨ï¼Œç”Ÿæˆ`Table`ã€‚æœ‰äº†CatalogåŠŸèƒ½ï¼Œæ•°æ®ç®¡ç†å›¢é˜Ÿå¯¹æ•°æ®æºæ›´äº†è§£ï¼Œä»–ä»¬å¯ä»¥æå‰åœ¨Catalogä¸­åˆ›å»ºPermanent Tableï¼Œæ³¨å†Œå¥½è¯¥è¡¨çš„Schemaã€æ³¨æ˜è¯¥è¡¨ä½¿ç”¨ä½•ç§åº•å±‚æŠ€æœ¯ã€å†™æ˜æ•°æ®å­˜å‚¨ä½ç½®ç­‰ï¼›æ•°æ®åˆ†æå›¢é˜Ÿå¯ä»¥å®Œå…¨ä¸ç”¨å…³å¿ƒè¿™äº›å…ƒæ•°æ®ä¿¡æ¯ï¼Œæ— éœ€äº†è§£è¿™ä¸ªè¡¨åˆ°åº•æ˜¯å­˜å‚¨åœ¨Kafkaè¿˜æ˜¯HDFSï¼Œç›´æ¥åœ¨è¿™ä¸ªè¡¨ä¸Šè¿›è¡ŒæŸ¥è¯¢ã€‚

æœ¬èŠ‚åç»­éƒ¨åˆ†å°†ä»‹ç»æ³¨å†Œè¡¨çš„å‡ ç§å¸¸è§æ–¹å¼ã€‚

## åœ¨Tableä¸Šæ‰§è¡Œè¯­å¥

### Table API

åŸºäº`Table`ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨Table APIæˆ–è€…SQLæ¥æŸ¥è¯¢å…¶ä¸­çš„æ•°æ®ã€‚Table APIå’Œç¼–ç¨‹è¯­è¨€ç»“åˆæ›´ç´§å¯†ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨`Table`ç±»ä¸Šä½¿ç”¨é“¾å¼è°ƒç”¨ï¼Œè°ƒç”¨`Table`ç±»ä¸­çš„å„ç§æ–¹æ³•ï¼Œæ‰§è¡Œå„ç±»å…³ç³»å‹æ“ä½œã€‚ä¸‹é¢çš„ä»£ç åœ¨`user_behavior`è¡¨ä¸Šè¿›è¡Œ`groupBy`å’Œ`select`æ“ä½œã€‚

```java
StreamTableEnvironment tEnv = ...
// åˆ›å»ºä¸€ä¸ªTemporaryTableï¼šuser_behavior
tEnv.connect(new FileSystem().path("..."))
        .withFormat(new Csv())
        .withSchema(schema)
        .createTemporaryTable("user_behavior");
Table userBehaviorTable = tEnv.from("user_behavior");

// åœ¨Tableä¸Šä½¿ç”¨Table APIæ‰§è¡Œå…³ç³»å‹æ“ä½œ
Table groupByUserId = userBehaviorTable.groupBy("user_id").select("user_id, COUNT(behavior) as cnt");
```

### SQL

æˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥åœ¨`Table`æ‰§è¡ŒSQLè¯­å¥ã€‚SQLæ ‡å‡†ä¸­å®šä¹‰äº†ä¸€ç³»åˆ—è¯­æ³•å’Œå…³é”®å­—ï¼Œå¼€å‘è€…å¯ä»¥åŸºäºSQLæ ‡å‡†æ¥ç¼–å†™SQLè¯­å¥ã€‚ä¸Table APIä¸­å‡½æ•°è°ƒç”¨çš„æ–¹å¼ä¸åŒï¼ŒSQLè¯­å¥æ˜¯çº¯æ–‡æœ¬å½¢å¼çš„ã€‚Flink SQLåŸºäºApache Calciteï¼ˆä»¥ä¸‹ç®€ç§°Calciteï¼‰ï¼Œå°†SQLè¯­å¥è½¬æ¢ä¸ºFlinkå¯æ‰§è¡Œç¨‹åºã€‚Calciteæ”¯æŒSQLæ ‡å‡†ï¼Œå› æ­¤Flink SQLä¹Ÿæ”¯æŒSQLæ ‡å‡†ã€‚

ä¸‹é¢çš„ä»£ç å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Flink SQLå¯¹ä¸€ä¸ª`Table`åšæŸ¥è¯¢ï¼š

```java
StreamTableEnvironment tEnv = ...
// åˆ›å»ºä¸€ä¸ªTemporaryTableï¼šuser_behavior
tEnv.connect(new FileSystem().path("..."))
        .withFormat(new Csv())
        .withSchema(schema)
        .createTemporaryTable("user_behavior");

// åœ¨Tableä¸Šä½¿ç”¨SQLæ‰§è¡Œå…³ç³»å‹æ“ä½œ
Table groupByUserId = tEnv.sqlQuery("SELECT user_id, COUNT(behavior) FROM user_behavior GROUP BY user_id");
```

ç”±äºTable APIå’ŒSQLéƒ½åŸºäº`Table`ç±»ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Table APIï¼Œç”Ÿæˆä¸€ä¸ª`Table`ï¼Œå†åœ¨æ­¤ä¹‹ä¸Šè¿›è¡ŒSQLæŸ¥è¯¢ï¼Œä¹Ÿå¯ä»¥å…ˆè¿›è¡ŒSQLæŸ¥è¯¢å¾—åˆ°ä¸€ä¸ª`Table`ï¼Œå†åœ¨æ­¤ä¹‹ä¸Šè°ƒç”¨Table APIã€‚ç”±æ­¤å¯è§ï¼ŒTable APIå’ŒSQLçš„ç»“åˆéå¸¸ç´§å¯†ã€‚æœ¬ä¹¦ååŠéƒ¨åˆ†å°†ä¸»è¦ä»‹ç»Flink SQLã€‚

## å°†Tableç»“æœè¾“å‡º

æˆ‘ä»¬å¯ä»¥å°†æŸ¥è¯¢ç»“æœé€šè¿‡`TableSink`è¾“å‡ºåˆ°å¤–éƒ¨ç³»ç»Ÿã€‚`TableSink`å’Œä¹‹å‰æåˆ°çš„Sinkå¾ˆåƒï¼Œå®ƒæ˜¯ä¸€ä¸ªæ•°æ®è¾“å‡ºçš„ç»Ÿä¸€æ¥å£ï¼Œå¯ä»¥å°†æ•°æ®ä»¥CSVã€Parquetã€Avroç­‰æ ¼å¼åºåˆ—åŒ–ï¼Œå¹¶å°†æ•°æ®å‘é€åˆ°å…³ç³»å‹æ•°æ®åº“ã€KVæ•°æ®åº“ã€æ¶ˆæ¯é˜Ÿåˆ—æˆ–æ–‡ä»¶ç³»ç»Ÿä¸Šã€‚`TableSink`ä¸Catalogã€Schemaç­‰æ¦‚å¿µç´§å¯†ç›¸å…³ã€‚ä¸‹é¢çš„ä»£ç å±•ç¤ºäº†å¦‚ä½•å°†æŸ¥è¯¢ç»“æœè¾“å‡ºåˆ°æ–‡ä»¶ç³»ç»Ÿã€‚

```java
StreamTableEnvironment tEnv = ...
tEnv.connect(new FileSystem().path("..."))
    .withFormat(new Csv().fieldDelimiter('|'))
    .withSchema(schema)
    .createTemporaryTable("CsvSinkTable");

// æ‰§è¡ŒæŸ¥è¯¢æ“ä½œï¼Œå¾—åˆ°ä¸€ä¸ªåä¸ºresultçš„Table
Table result = ...
// å°†resultå‘é€åˆ°åä¸ºCsvSinkTableçš„TableSink
result.insertInto("CsvSinkTable");
```

## æ‰§è¡Œä½œä¸š

ä»¥ä¸Šéƒ¨åˆ†æ˜¯ä¸€ä¸ªTable API & SQLä½œä¸šçš„æ ¸å¿ƒä»£ç ç¼–å†™é˜¶æ®µï¼Œä½†åƒä¸‡ä¸è¦å¿˜è®°è°ƒç”¨`execute`æ–¹æ³•æ¥æ‰§è¡Œè¿™ä¸ªä½œä¸šï¼Œå¦åˆ™ä½œä¸šæ— æ³•è¢«çœŸæ­£æ‰§è¡Œã€‚

![Table API & SQLä»è°ƒç”¨åˆ°æ‰§è¡Œçš„å¤§è‡´æµç¨‹](./img/table-internal.png)

ä¸Šå›¾ä¸ºTable API & SQLä»è°ƒç”¨åˆ°æ‰§è¡Œçš„å¤§è‡´æµç¨‹ã€‚ä¸€ä¸ªTable APIæˆ–è€…SQLè°ƒç”¨ç»è¿‡Planneræœ€ç»ˆè½¬åŒ–ä¸ºä¸€ä¸ª`JobGraph`ï¼ŒPlanneråœ¨ä¸­é—´èµ·åˆ°ä¸€ä¸ªè½¬æ¢å’Œä¼˜åŒ–çš„ä½œç”¨ã€‚å¯¹äºæµä½œä¸šå’Œæ‰¹ä½œä¸šï¼ŒBlink Planneråˆ†åˆ«æœ‰ç›¸åº”çš„ä¼˜åŒ–è§„åˆ™ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`TableEnvironment.explain(table)`æ¥å°†æŸ¥è¯¢è½¬åŒ–ä¸ºç‰©ç†æ‰§è¡Œè®¡åˆ’ã€‚

```java
// å£°æ˜ä¸€ä¸ªSQLæŸ¥è¯¢
Table groupByUserId = tEnv.sqlQuery(...)
  
String explanation = tEnv.explain(groupByUserId);
System.out.println(explanation);
```

æˆ‘ä»¬å¯ä»¥å¾—åˆ°ç›¸åº”çš„è¯­æ³•æ ‘ï¼ˆæœªä¼˜åŒ–çš„é€»è¾‘æ‰§è¡Œè®¡åˆ’ï¼‰ã€ä¼˜åŒ–åçš„é€»è¾‘æ‰§è¡Œè®¡åˆ’ä»¥åŠæœ€ç»ˆçš„ç‰©ç†æ‰§è¡Œè®¡åˆ’ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```
== Abstract Syntax Tree ==
LogicalAggregate(group=[{0}], behavior_cnt=[COUNT($1)])
+- LogicalProject(user_id=[$0], behavior=[$3])
   ...

== Optimized Logical Plan ==
GroupAggregate(groupBy=[user_id], select=[user_id, COUNT(behavior) AS behavior_cnt])
+- Exchange(distribution=[hash[user_id]])
   +- Calc(select=[user_id, behavior])
      ...

== Physical Execution Plan ==
Stage 1 : Data Source
	content : Source: KafkaTableSource(user_id, item_id, category_id, behavior, ts)

	Stage 2 : Operator
		content : SourceConversion(table=[default_catalog.default_database.user_behavior, source: [KafkaTableSource(user_id, item_id, category_id, behavior, ts)]], fields=[user_id, item_id, category_id, behavior, ts])
		ship_strategy : FORWARD
				...
```

ç»¼ä¸Šï¼ŒTable API & SQLä½¿ç”¨Plannerå°†ä½œä¸šè½¬åŒ–ä¸ºå…·ä½“å¯æ‰§è¡Œçš„ç¨‹åºã€‚

Flinkç¤¾åŒºè¯•å›¾ä¿è¯æµæ‰¹å¤„ç†ä»ä½¿ç”¨ä½“éªŒåˆ°å†…éƒ¨æ‰§è¡Œä¸Šçš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬æ›¾æåˆ°ï¼ŒFlink 1.10ç‰ˆæœ¬å­˜åœ¨ç€DataStream APIå’ŒDataSet APIå¹¶å­˜çš„ç°è±¡ï¼Œå³DataStream APIå¤„ç†æ— ç•Œæ•°æ®æµï¼ŒDataSet APIå¤„ç†æœ‰ç•Œæ•°æ®é›†ï¼›ä¹Ÿå­˜åœ¨ç€Flink Plannerå’ŒBlink Plannerå¹¶å­˜çš„ç°è±¡ã€‚å¼€æºç¤¾åŒºç‰ˆçš„Flink Planneréœ€è¦é€‚é…DataStream APIå’ŒDataSet APIï¼Œè€ŒBlink Plannerçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†æµæ‰¹ç»Ÿä¸€ï¼Œå®ƒè®¤ä¸ºæ‰¹å¤„ç†æ˜¯æµå¤„ç†çš„ä¸€ä¸ªå­é›†ï¼Œæ˜¯å¯¹æœ‰ç•Œæ•°æ®æµè¿›è¡Œå¤„ç†ã€‚å› æ­¤ï¼Œè¿™ä¸¤ç§Planneråœ¨å…·ä½“å®ç°ä¸Šæœ‰ä¸€äº›åŒºåˆ«ã€‚ä»åå­—ä¸­ä¹Ÿçœ‹å‡ºï¼ŒFlinkç¤¾åŒºå†³å®šé€æ¸å°†è€çš„Flink PlanneråºŸå¼ƒï¼Œå¹¶ä¸æ–­æ¨åŠ¨æµæ‰¹ä¸€ä½“åŒ–ã€‚å› æ­¤ï¼Œè¯»è€…åœ¨ä½¿ç”¨æ—¶æœ€å¥½æ ¹æ®æœ€æ–°æ–‡æ¡£æ¥é€‰æ‹©åˆé€‚çš„Plannerã€‚

## è·å–è¡¨çš„å…·ä½“æ–¹å¼

åœ¨Flink 1.10ä¸­ï¼ŒTable API & SQLä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’ä¸»è¦æœ‰ä¸¤å¤§ç±»æ–¹å¼ï¼š

1. åœ¨ç¨‹åºä¸­ä½¿ç”¨ä»£ç ç¼–ç¨‹é…ç½®
2. ä½¿ç”¨å£°æ˜å¼çš„è¯­è¨€ï¼Œå¦‚SQLçš„æ•°æ®åº“å®šä¹‰è¯­è¨€ï¼ˆData Definition Languageï¼ŒDDLï¼‰æˆ–YAMLæ–‡ä»¶ã€‚

æ— è®ºå“ªç±»æ–¹å¼ï¼Œéƒ½éœ€è¦é…ç½®å¤–éƒ¨ç³»ç»Ÿçš„å¿…è¦å‚æ•°ã€åºåˆ—åŒ–æ–¹å¼å’ŒSchemaã€‚

### ä»£ç é…ç½®æ–¹å¼

åœ¨ç¨‹åºä¸­ä½¿ç”¨ä»£ç é…ç½®çš„æ–¹å¼åˆå…·ä½“åˆ†ä¸ºï¼š

1. ä½¿ç”¨`connect`æ–¹æ³•è¿æ¥å¤–éƒ¨ç³»ç»Ÿ
2. å°†`DataStream`æˆ–`DataSet`è½¬æ¢ä¸º`Table`

å…¶ä¸­ï¼Œç¬¬ä¸€ç§æ”¯æŒçš„å¤–éƒ¨ç³»ç»Ÿæœ‰é™ï¼Œç›®å‰å¯ä»¥æ”¯æŒæ–‡ä»¶ç³»ç»Ÿã€Kafkaã€Elasticsearchå’ŒHBaseã€‚ç¬¬äºŒç§æ–¹å¼å’Œç¬¬ä¸ƒç« æ‰€æåˆ°çš„Flink Connectorä½¿ç”¨æ–¹æ³•ç›¸ä¼¼ï¼Œä»¥æµå¤„ç†ä¸ºä¾‹ï¼Œæˆ‘ä»¬éœ€è¦é¦–å…ˆè·å–ä¸€ä¸ª`DataStream`ï¼Œå†è¿›ä¸€æ­¥å°†å…¶è½¬åŒ–ä¸º`Table`ã€‚

æˆ‘ä»¬å…ˆçœ‹`connect`æ–¹æ³•ï¼Œä¸‹é¢çš„ä»£ç å±•ç¤ºäº†ä¸€ä¸ªæ¯”è¾ƒè¯¦ç»†çš„ä¾‹å­ï¼Œå®ƒä»ä¸€ä¸ªKafkaæ•°æ®æµä¸­è·å–`Table`ï¼Œæ•°æ®ä½¿ç”¨JSONåºåˆ—åŒ–ï¼Œæœ€ç»ˆåˆ›å»ºä¸€ä¸ªåä¸º`user_behavior`çš„è¡¨ã€‚

```java
tEnv
  // ä½¿ç”¨connectå‡½æ•°è¿æ¥å¤–éƒ¨ç³»ç»Ÿ
  .connect(
    new Kafka()
    .version("universal")     // å¿…å¡«ï¼ŒKafkaç‰ˆæœ¬ï¼Œåˆæ³•çš„å‚æ•°æœ‰"0.8", "0.9", "0.10", "0.11"æˆ–"universal"
    .topic("user_behavior")   // å¿…å¡«ï¼ŒTopicå
    .startFromLatest()        // é¦–æ¬¡æ¶ˆè´¹æ—¶æ•°æ®è¯»å–çš„ä½ç½®
    .property("zookeeper.connect", "localhost:2181")  // Kafkaè¿æ¥å‚æ•°
    .property("bootstrap.servers", "localhost:9092")
	)
  // åºåˆ—åŒ–æ–¹å¼ å¯ä»¥æ˜¯JSONã€Avroç­‰
  .withFormat(new Json())
  // æ•°æ®çš„Schema
  .withSchema(
    new Schema()
    .field("user_id", DataTypes.BIGINT())
    .field("item_id", DataTypes.BIGINT())
    .field("category_id", DataTypes.BIGINT())
    .field("behavior", DataTypes.STRING())
    .field("ts", DataTypes.TIMESTAMP(3))
	)
  // ä¸´æ—¶è¡¨çš„è¡¨åï¼Œåç»­å¯ä»¥åœ¨SQLè¯­å¥ä¸­ä½¿ç”¨è¿™ä¸ªè¡¨å
  .createTemporaryTable("user_behavior");
```

å…³äº`connect`ä»¥åŠå„ä¸ªå¤–éƒ¨ç³»ç»Ÿçš„å…·ä½“è¿æ¥æ–¹æ³•ï¼Œæœ¬ä¹¦å°†ä¸é€ä¸€è¦†ç›–ï¼Œè¯»è€…å¯ä»¥æ ¹æ®Flinkå®˜ç½‘çš„æœ€æ–°æ–‡æ¡£æ¥å­¦ä¹ ä½¿ç”¨ã€‚

`connect`æ–¹æ³•å¯ä»¥ç›´æ¥è¿æ¥å¤–éƒ¨æ•°æ®å¹¶åˆ›å»ºè¡¨ï¼Œæ­¤å¤–ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä¾æ‰˜DataStream APIï¼Œå°†ä¸€ä¸ª`DataStream`è½¬æ¢ä¸º`Table`ï¼š

```java
DataStream<UserBehavior> userBehaviorDataStream = ...
// å°†æ•°æ®æµè½¬æ¢ä¸ºä¸€ä¸ªè§†å›¾ï¼Œä½¿ç”¨UserBehaviorè¿™ä¸ªPOJOç±»å„å­—æ®µåä½œä¸ºuser_behaviorè¡¨çš„å­—æ®µå
tEnv.createTemporaryView("user_behavior", userBehaviorDataStream);
```

:::note
Flink 1.10çš„`TableEnvironment`ä¸æ”¯æŒå°†`DataStream`æˆ–`DataSet`è½¬æ¢ä¸º`Table`ï¼Œä½¿ç”¨æ­¤åŠŸèƒ½éœ€è¦ä½¿ç”¨`StreamTableEnvironment`æˆ–è€…`BatchTableEnvironment`ã€‚
:::

### å£°æ˜å¼æ–¹å¼

å¦ä¸€ç§è·å–è¡¨çš„æ–¹å¼æ˜¯ä½¿ç”¨SQL DDLæˆ–YAMLç­‰å£°æ˜å¼æ–¹å¼æ¥é…ç½®å¤–éƒ¨ç³»ç»Ÿã€‚

å¾ˆå¤šç³»ç»Ÿç”¨YAMLæ–‡ä»¶æ¥é…ç½®å‚æ•°ï¼Œä¸è¿‡ç›®å‰YAMLåªèƒ½å’ŒSQL Clienté…åˆï¼Œè€Œ1.10ç‰ˆæœ¬çš„SQL Clientæš‚æ—¶æ˜¯ä¸€ä¸ªæµ‹è¯•åŠŸèƒ½ï¼Œè¿˜ä¸èƒ½ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œè¿™é‡Œæš‚ä¸ä»‹ç»ï¼Œæ„Ÿå…´è¶£çš„è¯»è€…å¯ä»¥é€šè¿‡å®˜ç½‘æ–‡æ¡£äº†è§£ã€‚SQL DDLæ˜¯å¾ˆå¤šç†Ÿæ‚‰SQLçš„æœ‹å‹ç»å¸¸ä½¿ç”¨çš„åŠŸèƒ½ï¼Œæ¯”å¦‚`CREATE TABLE`ã€`DROP TABLE`ç­‰ï¼Œæ˜¯å¾ˆå¤šSQLç”¨æˆ·ç»å¸¸ä½¿ç”¨çš„è¯­å¥ã€‚åŒæ ·çš„ä¸€ä¸ªKafkaæ•°æ®æµï¼Œä½¿ç”¨SQL DDLå¯ä»¥è¿™æ ·å®šä¹‰ï¼š

```sql
CREATE TABLE user_behavior (
    -- è¡¨çš„Schema
    user_id BIGINT,
    item_id BIGINT,
    category_id BIGINT,
    behavior STRING,
    ts TIMESTAMP(3),
    WATERMARK FOR ts as ts - INTERVAL '5' SECOND  -- å®šä¹‰Watermark tsä¸ºEventTime
) WITH (
    -- å¤–éƒ¨ç³»ç»Ÿè¿æ¥å‚æ•°
    'connector.type' = 'kafka',
    'connector.version' = 'universal',  -- Kafkaç‰ˆæœ¬
    'connector.topic' = 'user_behavior',  -- Kafka Topic
    'connector.startup-mode' = 'latest-offset',  -- ä»æœ€è¿‘çš„offsetå¼€å§‹è¯»å–æ•°æ®
    'connector.properties.zookeeper.connect' = 'localhost:2181',  -- Kafkaè¿æ¥å‚æ•°
    'connector.properties.bootstrap.servers' = 'localhost:9092', 
     -- åºåˆ—åŒ–æ–¹å¼
  	'format.type' = 'json'  -- æ•°æ®æºæ ¼å¼ä¸º json
);
```

å°†ä¸Šé¢çš„SQLè¯­å¥ç²˜è´´åˆ°`tEnv.sqlUpdate("CREATE TABLE ...")`ä¸­ï¼Œæ”¾åœ¨ä¸»é€»è¾‘ä¸­æ‰§è¡Œå³å¯ã€‚æˆ‘ä»¬å°†åœ¨[SQL DDL](sql-ddl.md)éƒ¨åˆ†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨è¿™äº›è¯­å¥åˆ›å»ºè¡¨ã€‚